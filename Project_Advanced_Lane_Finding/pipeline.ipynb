{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get imports\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper functions\n",
    "import camera_calibrator\n",
    "import distortion_correction\n",
    "import image_binary_gradient\n",
    "import perspective_transform\n",
    "import detect_lane_pixels\n",
    "import measure_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to undistort\n",
    "calibration1 = ('./camera_cal/calibration1.jpg')\n",
    "straight_lines1 = ('./test_images/straight_lines1.jpg')\n",
    "straight_lines2 = ('./test_images/straight_lines2.jpg')\n",
    "test1 = ('./test_images/test1.jpg')\n",
    "test2 = ('./test_images/test2.jpg')\n",
    "test3 = ('./test_images/test3.jpg')\n",
    "test4 = ('./test_images/test4.jpg')\n",
    "test5 = ('./test_images/test5.jpg')\n",
    "test6 = ('./test_images/test6.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(image):\n",
    "    \n",
    "    # Get matrix from calibration\n",
    "    mtx, dist = camera_calibrator.get_calibration_matrix()\n",
    "    \n",
    "    \n",
    "    # Smoothen the lanes using clahe\n",
    "    LUV = image\n",
    "    lab = cv2.cvtColor(LUV, cv2.COLOR_RGB2LUV)\n",
    "    lab_planes = cv2.split(lab)\n",
    "    gridsize = 3\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(gridsize,gridsize))\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "    lab = cv2.merge(lab_planes)\n",
    "    image_original = cv2.cvtColor(lab, cv2.COLOR_LUV2RGB)\n",
    "\n",
    "\n",
    "    \n",
    "    # Undistoretd image \n",
    "    undist_img = distortion_correction.get_undistorted_image(image_original, mtx, dist, gray_scale=False)#image_original\n",
    "    \n",
    "    # Binary Image \n",
    "    \n",
    "    color_binary, binary_image = image_binary_gradient.get_binary_image(undist_img)\n",
    "\n",
    "    \n",
    "    # Perspective trasform\n",
    "    top_down = perspective_transform.get_transformed_perspective(binary_image)  \n",
    "    \n",
    "    # Warp the color zone back to original image space using inverse perspective matrix (Minv)\n",
    "    color_zone_warp = measure_curvature.get_color_zone_warp(top_down)\n",
    "    newwarp  = perspective_transform.get_original_perspective(color_zone_warp)\n",
    "\n",
    "    original_img = cv2.addWeighted(image_original, 1, newwarp, 0.3, 0)#image_original\n",
    "    result = measure_curvature.add_text(original_img, top_down)\n",
    "    \n",
    "    # If gray scale convert to triple channel format\n",
    "    \n",
    "    if len(result.shape) == 2:\n",
    "        result = np.dstack((original_img,)*3)\n",
    "\n",
    "    # If binary image, scale to full 8-bit values\n",
    "    if np.max(result) <= 1:\n",
    "        result *= 255\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = lambda fname: mpimg.imread(fname)\n",
    "result = pipeline(img(test4))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test pipeline on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'project_video.mp4'\n",
    "# output = 'videos_out/project_video_processed.mp4'\n",
    "\n",
    "# clip1 = VideoFileClip(fname)\n",
    "# clip = clip1.fl_image(pipeline)\n",
    "# %time clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Challange video\n",
    "\n",
    "# clip2 = VideoFileClip('challenge_video.mp4')\n",
    "# clip_challenge = clip2.fl_image(pipeline)\n",
    "# %time clip_challenge.write_videofile('videos_out/challenge_video_processed.mp4', audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
